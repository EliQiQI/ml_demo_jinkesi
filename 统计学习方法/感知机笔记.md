# 感知机
> 二类分类的线性模型  
> 输入为实例的特征向量  
> 输出为实例的类别  
> 感知机对应于输入空间(特征空间)将实例划分为正负两类的分离超平面,属于判别模型

给定训练数据集
$$
T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
$$
其中,
$$
x_i\in\chi=R^n,y_i\in\gamma=\{+1,-1\},i=1,2,...,N.
$$
感知机`sign(w·x+b)`学习的损失函数定义为:
$$
L(w,x) = - \Sigma_{x_i\in M}y_i(w·x_i+b)                                                (式2.4)
$$
其中$M$为误分类点的集合.这个损失函数就是感知机学习的经验风险函数.

**感知机学习的策略是在假设空间中选取使损失函数最小的模型参数w,b**

## 感知机学习算法的原始形式

感知机学习算法是对以下最优化问题的算法.给定一个训练数据集
$$
T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
$$
其中,$x_i\in\chi=R^n$,$y_i\in\gamma=\{-1,1\}$,$i=1,2,...,N$,求参数$w$,$b$,使其为以下损失函数极小化问题的解
$$
min_{w,b}L(w,b) = - \Sigma_{x_i\in M}y_i(w·x_i+b)
$$
其中M为误分类点的集合.

### 感知机学习算法的原始形式:

输入:训练数据集$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$,其中$x_i\in\chi=R^n$​,$y_i\in\gamma=\{-1,1\}$,$i=1,2,···,N$,学习率$\eta(0<\eta\leq1)$;

输出:$w,b$;感知机模型$f(x)=sign(w·x+b)$.

(1)选取初值$w_0$,$b_0$

(2)在训练集中选取数据$(x_i,y_i)$

(3)如果$y_i(w·x_i+b)\leq0$
$$
w\leftarrow w+\eta y_i x_i
$$

$$
b\leftarrow b+\eta y_i
$$

(4)转至(2),直至训练集中没有误分类点

### 感知机学习算法的对偶形式

输入:线性可分的数据集$T={(x_1,y_1),(x_2,y_2),...(x_N,y_N)}$,其中$x_i\in R^n,y_i\in\{-1,+1\}$,$i=1,2,...,N$;学习率$\eta(0<\eta\leq 1)$:

输出:$\alpha,b$:感知机模型$f(x)=sign(\Sigma_{j=1}^N\alpha_j y_j x_j ·x+b)$​,其中$\alpha=(\alpha_1,\alpha_2,···,\alpha_n)^T$

(1) $\alpha\leftarrow 0,b\leftarrow 0$​

(2)在训练集中选取数据$(x_i,y_i)$

(3)如果$y_i(\Sigma_{j=1}^N\alpha_j y_j x_j ·x_i+b)\leq 0$
$$
\alpha_i \leftarrow \alpha_i + \eta
$$

$$
b \leftarrow b + \eta y_i
$$



(4)转至(2)直到没有误分类数据
